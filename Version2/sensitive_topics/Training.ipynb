{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "\n",
    "from transformers.trainer_callback import EarlyStoppingCallback\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/multilabel_data/publication2/train.csv')\n",
    "df_val = pd.read_csv('../../data/multilabel_data/publication2/val.csv')\n",
    "df_test = pd.read_csv('../../data/multilabel_data/publication2/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>offline_crime</th>\n",
       "      <th>online_crime</th>\n",
       "      <th>drugs</th>\n",
       "      <th>gambling</th>\n",
       "      <th>pornography</th>\n",
       "      <th>prostitution</th>\n",
       "      <th>slavery</th>\n",
       "      <th>suicide</th>\n",
       "      <th>terrorism</th>\n",
       "      <th>weapons</th>\n",
       "      <th>body_shaming</th>\n",
       "      <th>health_shaming</th>\n",
       "      <th>politics</th>\n",
       "      <th>racism</th>\n",
       "      <th>religion</th>\n",
       "      <th>sexual_minorities</th>\n",
       "      <th>sexism</th>\n",
       "      <th>social_injustice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Убийства и мы все знаем что убийца там ☝️</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>...а потом граждане возмущаются что ктото кое ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Да преступление не тяжкое, могут под домашний ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Не льсти себе: Вот моя бывшая вообще мило пост...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Стать правителем и посадить их всех в тюрьму. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  offline_crime  \\\n",
       "0          Убийства и мы все знаем что убийца там ☝️              1   \n",
       "1  ...а потом граждане возмущаются что ктото кое ...              1   \n",
       "2  Да преступление не тяжкое, могут под домашний ...              1   \n",
       "3  Не льсти себе: Вот моя бывшая вообще мило пост...              1   \n",
       "4  Стать правителем и посадить их всех в тюрьму. ...              1   \n",
       "\n",
       "   online_crime  drugs  gambling  pornography  prostitution  slavery  suicide  \\\n",
       "0             0      0         0            0             0        0        0   \n",
       "1             0      0         0            0             0        0        0   \n",
       "2             0      0         0            0             0        0        0   \n",
       "3             0      0         0            0             0        0        0   \n",
       "4             0      0         0            0             0        0        0   \n",
       "\n",
       "   terrorism  weapons  body_shaming  health_shaming  politics  racism  \\\n",
       "0          0        0             0               0         0       0   \n",
       "1          0        0             0               0         0       0   \n",
       "2          0        0             0               0         0       0   \n",
       "3          0        0             0               0         0       0   \n",
       "4          0        0             0               0         0       0   \n",
       "\n",
       "   religion  sexual_minorities  sexism  social_injustice  \n",
       "0         0                  0       0                 0  \n",
       "1         0                  0       0                 0  \n",
       "2         0                  0       0                 0  \n",
       "3         0                  0       0                 0  \n",
       "4         0                  0       0                 0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['offline_crime',\n",
       " 'online_crime',\n",
       " 'drugs',\n",
       " 'gambling',\n",
       " 'pornography',\n",
       " 'prostitution',\n",
       " 'slavery',\n",
       " 'suicide',\n",
       " 'terrorism',\n",
       " 'weapons',\n",
       " 'body_shaming',\n",
       " 'health_shaming',\n",
       " 'politics',\n",
       " 'racism',\n",
       " 'religion',\n",
       " 'sexual_minorities',\n",
       " 'sexism',\n",
       " 'social_injustice']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "necessary_columns = list(df.columns)[1:] \n",
    "necessary_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(dataframe):\n",
    "    labels =[]\n",
    "    for i, el in dataframe.iterrows():\n",
    "        current_sample_labels = []\n",
    "        any_class = False\n",
    "        for clm in necessary_columns:\n",
    "            if el[clm] == 1:\n",
    "                any_class = True\n",
    "                current_sample_labels.append(clm)\n",
    "        if any_class == False:\n",
    "            current_sample_labels.append(\"none\")\n",
    "        current_sample_labels = ','.join(current_sample_labels)\n",
    "        labels.append(current_sample_labels)\n",
    "    return labels\n",
    "train_labels = get_labels(df)\n",
    "val_labels = get_labels(df_val)\n",
    "test_labels = get_labels(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_adjusted = pd.DataFrame({'text':list(df['text']), 'labels':train_labels})\n",
    "df_val_adjusted = pd.DataFrame({'text':list(df_val['text']), 'labels':val_labels})\n",
    "df_test_adjusted = pd.DataFrame({'text':list(df_test['text']), 'labels':test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict()\n",
    "mapping['none'] = 0\n",
    "\n",
    "for label in train_labels:\n",
    "    if label not in mapping:\n",
    "        mapping[label] = len(mapping)\n",
    "\n",
    "for label in test_labels:\n",
    "    if label not in mapping:\n",
    "        mapping[label] = len(mapping)\n",
    "        \n",
    "for label in val_labels:\n",
    "    if label not in mapping:\n",
    "        mapping[label] = len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_adjusted['class'] = df_train_adjusted['labels'].apply(lambda x: mapping[x])\n",
    "df_test_adjusted['class'] = df_test_adjusted['labels'].apply(lambda x: mapping[x])\n",
    "df_val_adjusted['class'] = df_val_adjusted['labels'].apply(lambda x: mapping[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Требуют забрать заявление об увольнении с угрозой</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>да расстреляют на месте, за сопротивление</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Белорусы в форме омона бьют белорусов в штатском</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Одного нужно захватить, чтобы узнать мотивы со...</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>сел в тюрьму за кражу глазурованного сырка</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>Бляяяяяя, он опять порвался, что совок унижают</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>Кормилица И в пир и в мир и в добрые люди</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>Очень интересная статья, про развертки даже я ...</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>Бан блять кроль за такую хуйню СХС КРОЛ</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>это не в хитакисе, это спец код в ядре управле...</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>692 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text         labels  class\n",
       "0    Требуют забрать заявление об увольнении с угрозой  offline_crime      1\n",
       "1            да расстреляют на месте, за сопротивление  offline_crime      1\n",
       "2     Белорусы в форме омона бьют белорусов в штатском  offline_crime      1\n",
       "3    Одного нужно захватить, чтобы узнать мотивы со...  offline_crime      1\n",
       "4           сел в тюрьму за кражу глазурованного сырка  offline_crime      1\n",
       "..                                                 ...            ...    ...\n",
       "687     Бляяяяяя, он опять порвался, что совок унижают           none      0\n",
       "688          Кормилица И в пир и в мир и в добрые люди           none      0\n",
       "689  Очень интересная статья, про развертки даже я ...           none      0\n",
       "690            Бан блять кроль за такую хуйню СХС КРОЛ           none      0\n",
       "691  это не в хитакисе, это спец код в ядре управле...           none      0\n",
       "\n",
       "[692 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_val = df_val_adjusted['labels'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train_adjusted['text'].tolist()\n",
    "y_train = df_train_adjusted['class'].tolist()\n",
    "x_test = df_test_adjusted['text'].tolist()\n",
    "y_test = df_test_adjusted['class'].tolist()\n",
    "x_val = df_val_adjusted['text'].tolist()\n",
    "y_val = df_val_adjusted['class'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnsafeData(Dataset):\n",
    "\n",
    "    def __init__(self, texts, targets, tokenizer, max_len):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.texts = texts\n",
    "        self.targets = targets        \n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.texts)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.texts[index]\n",
    "\n",
    "        enc_dict = self.tokenizer(x, truncation=True, max_length=self.max_len, padding='max_length')\n",
    "      \n",
    "        item = {key: torch.tensor(val).long() for key, val in enc_dict.items()}\n",
    "        item['labels'] = torch.tensor(self.targets[index]).long()\n",
    "\n",
    "        return item "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'DeepPavlov/rubert-base-cased-conversational'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased-conversational and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels = len(mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 19 12:36:46 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.102.04   Driver Version: 450.102.04   CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 27%   27C    P8    11W / 260W |      3MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:1B:00.0 Off |                  N/A |\n",
      "| 27%   26C    P8     9W / 260W |      3MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:1C:00.0 Off |                  N/A |\n",
      "| 27%   29C    P8     5W / 260W |   1466MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 27%   27C    P8    12W / 260W |   1218MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  Off  | 00000000:3D:00.0 Off |                  N/A |\n",
      "| 75%   71C    P2   256W / 260W |   3020MiB / 11019MiB |     98%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  Off  | 00000000:3E:00.0 Off |                  N/A |\n",
      "| 27%   31C    P8    15W / 260W |   1588MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  Off  | 00000000:40:00.0 Off |                  N/A |\n",
      "| 59%   62C    P2   160W / 260W |   7798MiB / 11019MiB |     47%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  Off  | 00000000:41:00.0 Off |                  N/A |\n",
      "| 27%   27C    P8    14W / 260W |   7344MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "device= torch.device(\"cuda:3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = UnsafeData(x_train, y_train, tokenizer, max_len = 60)\n",
    "test_dataset = UnsafeData(x_test, y_test, tokenizer, max_len = 60)\n",
    "val_dataset = UnsafeData(x_val, y_val, tokenizer, max_len = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31130, 1481, 692)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  2270, 47970,   994,   846,  2181,   132,   458,  2396,  7370,\n",
       "          1536,  1967,   838,  3005,   132,  1235,   322, 19121,   322, 28114,\n",
       "           846,  2181,   132, 75832,   371,   801,  5827,   130,  1064,   802,\n",
       "          7134,   322, 37442,   846,  2181,  1981,  6080,   132,  1190,  4302,\n",
       "           340, 11728,  1143,  2838,  1088, 11757,   132,   102,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(1)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['offline_crime',\n",
       " 'online_crime',\n",
       " 'drugs',\n",
       " 'gambling',\n",
       " 'pornography',\n",
       " 'prostitution',\n",
       " 'slavery',\n",
       " 'suicide',\n",
       " 'terrorism',\n",
       " 'weapons',\n",
       " 'body_shaming',\n",
       " 'health_shaming',\n",
       " 'politics',\n",
       " 'racism',\n",
       " 'religion',\n",
       " 'sexual_minorities',\n",
       " 'sexism',\n",
       " 'social_injustice',\n",
       " 'none']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_list = necessary_columns + ['none']\n",
    "topics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vaiables_id2topic_dict = {val:key for key, val in mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"id2topic.json\",\"w\") as f:\n",
    "    json.dump(target_vaiables_id2topic_dict, f, indent = 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_vaiables_id2topic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_multilabel(y, is_pred = False):\n",
    "    y_adjusted = []\n",
    "    for y_c in y:\n",
    "        y_test_curr = [0]*19\n",
    "        if is_pred == True:\n",
    "            y_c = target_vaiables_id2topic_dict[np.argmax(y_c)]\n",
    "        else:\n",
    "            y_c = target_vaiables_id2topic_dict[y_c]\n",
    "        for tag in y_c.split(\",\"):\n",
    "            topic_index = topics_list.index(tag)\n",
    "            y_test_curr[topic_index] = 1\n",
    "        y_adjusted.append(y_test_curr)\n",
    "    return y_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    labels = adjust_multilabel(labels, is_pred = False)\n",
    "    preds = pred.predictions\n",
    "    preds = adjust_multilabel(preds, is_pred = True)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted', zero_division = 0)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='/multi_model/publ',\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    logging_steps = 600,\n",
    "    evaluation_strategy = 'steps',\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    save_steps = 500,\n",
    "    eval_steps = 500,\n",
    "    metric_for_best_model  = 'f1',\n",
    "    greater_is_better = True,\n",
    "    load_best_model_at_end = True    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def cleanup():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.add_callback(EarlyStoppingCallback(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='2440' max='2440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2440/2440 49:18, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.580844</td>\n",
       "      <td>0.504335</td>\n",
       "      <td>0.618515</td>\n",
       "      <td>0.796880</td>\n",
       "      <td>0.546571</td>\n",
       "      <td>2.862300</td>\n",
       "      <td>241.767000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.443700</td>\n",
       "      <td>2.351733</td>\n",
       "      <td>0.510116</td>\n",
       "      <td>0.661653</td>\n",
       "      <td>0.737713</td>\n",
       "      <td>0.609007</td>\n",
       "      <td>3.181300</td>\n",
       "      <td>217.523000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.553800</td>\n",
       "      <td>2.403322</td>\n",
       "      <td>0.531792</td>\n",
       "      <td>0.680419</td>\n",
       "      <td>0.745736</td>\n",
       "      <td>0.634596</td>\n",
       "      <td>3.179300</td>\n",
       "      <td>217.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.299900</td>\n",
       "      <td>2.488272</td>\n",
       "      <td>0.534682</td>\n",
       "      <td>0.690131</td>\n",
       "      <td>0.742240</td>\n",
       "      <td>0.653019</td>\n",
       "      <td>3.186900</td>\n",
       "      <td>217.138000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2440, training_loss=0.863366361328813, metrics={'train_runtime': 2959.4311, 'train_samples_per_second': 0.824, 'total_flos': 19965548168676000, 'epoch': 10.0})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='24' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2440 < 2441; dropping {'eval/loss': 2.488271951675415, 'eval/accuracy': 0.5346820809248555, 'eval/f1': 0.690130843519044, 'eval/precision': 0.7422397670469699, 'eval/recall': 0.6530194472876152, 'eval/runtime': 3.3282, 'eval/samples_per_second': 207.922, 'train/epoch': 10.0}.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.488271951675415,\n",
       " 'eval_accuracy': 0.5346820809248555,\n",
       " 'eval_f1': 0.690130843519044,\n",
       " 'eval_precision': 0.7422397670469699,\n",
       " 'eval_recall': 0.6530194472876152,\n",
       " 'eval_runtime': 3.3282,\n",
       " 'eval_samples_per_second': 207.922,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('multi-class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка на val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "pred = trainer.predict(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = pred.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31130, 1481, 692, 692)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df),len(df_test), len(df_val), len(adjust_multilabel(y_val, is_pred = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    offline_crime       0.64      0.54      0.58        52\n",
      "     online_crime       0.46      0.43      0.44        14\n",
      "            drugs       0.88      0.88      0.88        41\n",
      "         gambling       0.50      0.50      0.50         2\n",
      "      pornography       0.77      0.68      0.72        87\n",
      "     prostitution       0.87      0.80      0.84        41\n",
      "          slavery       0.72      0.87      0.79        15\n",
      "          suicide       0.50      0.67      0.57         3\n",
      "        terrorism       0.50      0.39      0.44        18\n",
      "          weapons       0.90      0.94      0.92        65\n",
      "     body_shaming       0.86      0.67      0.75        48\n",
      "   health_shaming       0.86      0.65      0.74        49\n",
      "         politics       0.73      0.56      0.63       109\n",
      "           racism       0.82      0.59      0.69        86\n",
      "         religion       0.90      0.80      0.84        44\n",
      "sexual_minorities       0.69      0.55      0.61        40\n",
      "           sexism       0.63      0.75      0.68        56\n",
      " social_injustice       0.57      0.37      0.45        81\n",
      "             none       0.67      0.69      0.68       126\n",
      "\n",
      "        micro avg       0.74      0.65      0.69       977\n",
      "        macro avg       0.71      0.65      0.67       977\n",
      "     weighted avg       0.74      0.65      0.69       977\n",
      "      samples avg       0.76      0.70      0.71       977\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(adjust_multilabel(y_val, is_pred = False), adjust_multilabel(pr, is_pred = True),\n",
    "                           target_names=topics_list, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка на test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "pred2 = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr2 = pred2.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    offline_crime       0.65      0.55      0.60       132\n",
      "     online_crime       0.50      0.46      0.48        37\n",
      "            drugs       0.87      0.90      0.88        87\n",
      "         gambling       0.50      0.67      0.57         6\n",
      "      pornography       0.73      0.59      0.65       204\n",
      "     prostitution       0.75      0.69      0.72        91\n",
      "          slavery       0.72      0.72      0.73        40\n",
      "          suicide       0.33      0.29      0.31         7\n",
      "        terrorism       0.68      0.57      0.62        47\n",
      "          weapons       0.89      0.83      0.86       138\n",
      "     body_shaming       0.90      0.67      0.77       109\n",
      "   health_shaming       0.84      0.55      0.66       108\n",
      "         politics       0.68      0.54      0.60       241\n",
      "           racism       0.81      0.59      0.68       204\n",
      "         religion       0.94      0.72      0.81       102\n",
      "sexual_minorities       0.69      0.46      0.55       102\n",
      "           sexism       0.66      0.64      0.65       132\n",
      " social_injustice       0.56      0.37      0.45       181\n",
      "             none       0.62      0.67      0.64       250\n",
      "\n",
      "        micro avg       0.72      0.61      0.66      2218\n",
      "        macro avg       0.70      0.60      0.64      2218\n",
      "     weighted avg       0.73      0.61      0.66      2218\n",
      "      samples avg       0.75      0.66      0.68      2218\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(adjust_multilabel(y_test, is_pred = False), adjust_multilabel(pr2, is_pred = True),\n",
    "                           target_names=topics_list, zero_division = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git', '.gitattributes']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path = \"../../../../../russian-sensitive-topics\"\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../../../../../russian-sensitive-topics/tokenizer_config.json',\n",
       " '../../../../../russian-sensitive-topics/special_tokens_map.json',\n",
       " '../../../../../russian-sensitive-topics/vocab.txt',\n",
       " '../../../../../russian-sensitive-topics/added_tokens.json')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tf_model = TFBertForSequenceClassification.from_pretrained(path, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.save_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
